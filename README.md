# Hyperliquid Utility Scripts

## Scripts Overview

This repository contains utility scripts for managing and monitoring Hyperliquid validators. Below is a detailed description of the available scripts:

### 1. `unjail_validator.sh`

This script is used to automatically unjail a validator on the Hyperliquid Testnet. It periodically checks the validator's status and sends an unjail action if the validator is jailed and the unjailable period has passed.

#### Usage:
1. Set the following environment variables in the script:
   - `VALIDATOR_NAME`: The name of the validator to monitor.
   - `SIGNING_KEY`: The signing key used to send the unjail action.
   - `INTERVAL`: The interval (in seconds) at which the script checks the validator's status (default is 10 seconds).

2. Run the script:
   ```bash
   ./unjail_validator.sh
   ```

#### Dependencies:
- `jq`: A lightweight and flexible command-line JSON processor. The script will attempt to install it if not already available.

#### Key Features:
- Fetches validator information from the Hyperliquid Testnet API.
- Checks if the validator is jailed and whether the unjailable period has passed.
- Sends an unjail action using the `hl-node` command inside a Docker container.

---

### 2. `get_validator_ip_addresses.sh`

This script is used to extract the IP addresses of nodes from the periodic ABCI state files generated by the Hyperliquid node. It monitors for new state files and processes them to extract relevant information.

#### Usage:
1. Run the script:
   ```bash
   ./get_validator_ip_addresses.sh
   ```

#### Key Features:
- Monitors the `~/hl/data/periodic_abci_states` directory inside the `hyperliquid-node-1` Docker container for new state files.
- Processes the latest `.rmp` file using the `translate-abci-state` command to generate a JSON output.
- Searches for `node_ip` entries in the JSON output and saves the results to a file named `grep_output.txt` on the host machine.

#### Output:
- The extracted IP addresses and related information are saved in `grep_output.txt` in the current directory.

#### Notes:
- The script ensures that only the latest state files are processed by comparing timestamps.
- It removes temporary files in the `/tmp` directory of the container before processing new files.

---

### 3. `pruner.sh`

This script is used to clean up old node data files in the specified directory to free up disk space. It runs continuously and deletes files older than 3 days.

#### Usage:
1. Set the `NODE_DATA_DIR` variable in the script to the directory containing the node data:
   ```bash
   NODE_DATA_DIR="/path/to/your/node-data"
   ```

2. Run the script:
   ```bash
   ./pruner.sh
   ```

#### Key Features:
- Deletes files in the specified directory that are older than 3 days.
- Runs as a background process, checking for old files every 24 hours.
- Logs the list of deleted files to `/tmp/deletelist`.

#### Notes:
- Ensure the `NODE_DATA_DIR` variable is set correctly to avoid accidental deletion of important files.
- The script uses the `find` command to identify and delete old files.

---

### Prerequisites for All Scripts:
- Docker must be installed and running.
- The `hyperliquid-node-1` container must be active and accessible (for scripts interacting with the container).
- Ensure the `hl-node` binary is available inside the container.

### Disclaimer:
These scripts are designed for use in the Hyperliquid Testnet environment. Ensure you have the necessary permissions and backups before running them in a production environment.
